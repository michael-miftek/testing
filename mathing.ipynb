{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "def make_index(file):\n",
    "    origins = []\n",
    "    current_origin = 0\n",
    "\n",
    "    original_position = file.tell()\n",
    "    file.seek(0)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            pickle.load(file)\n",
    "            origins.append(current_origin)\n",
    "            current_origin = file.tell()\n",
    "        except EOFError:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e} in daqfile initializing index of file\")\n",
    "\n",
    "    #print(f\"Make index {type(file)}\")\n",
    "    file.seek(original_position)\n",
    "\n",
    "    return origins\n",
    "\n",
    "\n",
    "filename = '20240827_FakeWBC_Vtrigger.npy'\n",
    "\n",
    "try:\n",
    "    file = open(filename, 'r+b')\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e} in daqfile for playback\")\n",
    "    raise\n",
    "\n",
    "origins = make_index(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16065"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#COUNT\n",
    "if(origins is None):\n",
    "    raise Exception(\"Daqfile: file has not been initialized\")\n",
    "len(origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'dict'>\n",
      "dict_keys(['time', 'event'])\n",
      "2500\n",
      "36\n",
      "500\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "#GET\n",
    "file.seek(origins[0])\n",
    "packet = pickle.load(file)\n",
    "print(len(packet))\n",
    "print(type(packet))\n",
    "print(packet.keys())\n",
    "print(len(packet['event']['data']['adc_data']))\n",
    "print(len(packet['event']['data']['adc_data'][0]))\n",
    "temp = packet['event']['data']['adc_data'][500:1000]\n",
    "print(len(temp))\n",
    "print(len(temp[0:500]))\n",
    "# data = []\n",
    "# for i in range(6):\n",
    "#     file.seek(origins[i])\n",
    "#     packet = pickle.load(file)\n",
    "#     data.append(packet['event']['data']['adc_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['375 nm', '488 nm', 'top right', '398 nm', '405 nm', '422 nm']\n",
      "['top right', '488 nm', '422 nm', '405 nm', '398 nm', '375 nm']\n",
      "{'top right': 3, '488 nm': 1, '422 nm': 7, '405 nm': 6, '398 nm': 5, '375 nm': 0}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'top right': 3, '488 nm': 1, '422 nm': 7, '405 nm': 6, '398 nm': 5, '375 nm': 0, 'nc': [2, 4, 8, 9]}\n",
      "7\n",
      "dict_keys(['top right', '488 nm', '422 nm', '405 nm', '398 nm', '375 nm', 'nc'])\n",
      "6\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "string1 = [\"375 nm\", \"488 nm\", \"nc\", \"top right\", \"nc\", \"398 nm\", \"405 nm\", \"422 nm\", \"nc\", \"nc\"]\n",
    "string2 = {}\n",
    "tempstr = []\n",
    "for n in range(len(string1)):\n",
    "    if string1[n].lower() != \"nc\":\n",
    "        string2[f\"{string1[n]}\"] = n\n",
    "    else:\n",
    "        tempstr.append(n)\n",
    "\n",
    "temp = list(string2.keys())\n",
    "print(temp)\n",
    "temp.sort()\n",
    "temp.reverse()\n",
    "print(temp)\n",
    "sorted_dict = {i : string2[i] for i in temp}\n",
    "\n",
    "print(sorted_dict)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "sorted_dict[\"nc\"] = tempstr\n",
    "print(sorted_dict)\n",
    "print(len(sorted_dict))\n",
    "print(sorted_dict.keys())\n",
    "print(sorted_dict[\"405 nm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAQ1 DAQ2 DAQ3\n",
      "['DAQ1', 'DAQ2', 'DAQ3']\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "test = \"['DAQ1', 'DAQ2', 'DAQ3']\"\n",
    "\n",
    "for i in [\"'\", \"[\", \"]\", \",\"]:\n",
    "    test = test.replace(i, \"\")\n",
    "# test = test.replace(\"'\", \"\")\n",
    "# test = test.replace(\"[\", \"\")\n",
    "# test = test.replace(\"]\", \"\")\n",
    "# test = test.replace(\",\", \"\")\n",
    "print(test)\n",
    "newtest = test.split(\" \")\n",
    "print(newtest)\n",
    "print(type(newtest[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "boo\n",
      "Error: DAQ1 != channel 1\n",
      "Error: DAQ1 != channel 2\n",
      "Error: DAQ1 != channel 3\n",
      "Error: DAQ1 != channel 4\n",
      "Error: DAQ1 != channel 5\n",
      "Error: DAQ1 != channel 6\n",
      "Error: DAQ1 != channel 7\n",
      "Error: DAQ1 != channel 8\n",
      "Error: DAQ1 != channel 9\n",
      "Error: DAQ1 != channel 10\n",
      "Error: DAQ1 != channel 11\n",
      "i: 1\n",
      "Error: DAQ2 != channel 12\n",
      "Error: DAQ2 != channel 13\n",
      "Error: DAQ2 != channel 14\n",
      "Error: DAQ2 != channel 15\n",
      "Error: DAQ2 != channel 16\n",
      "Error: DAQ2 != channel 17\n",
      "Error: DAQ2 != channel 18\n",
      "Error: DAQ2 != channel 19\n",
      "Error: DAQ2 != channel 20\n",
      "Error: DAQ2 != channel 21\n",
      "Error: DAQ2 != channel 22\n",
      "Error: DAQ2 != channel 23\n",
      "i: 2\n",
      "Error: DAQ3 != channel 24\n",
      "Error: DAQ3 != channel 25\n",
      "Error: DAQ3 != channel 26\n",
      "Error: DAQ3 != channel 27\n",
      "Error: DAQ3 != channel 28\n",
      "Error: DAQ3 != channel 29\n",
      "Error: DAQ3 != channel 30\n",
      "Error: DAQ3 != channel 31\n",
      "Error: DAQ3 != channel 32\n",
      "Error: DAQ3 != channel 33\n",
      "Error: DAQ3 != channel 34\n",
      "Error: DAQ3 != channel 35\n"
     ]
    }
   ],
   "source": [
    "lt = [('DAQ1.1', 'DAQ 0 Channel 0'), ('channel 1', 'DAQ 0 Channel 1'), ('channel 2', 'DAQ 0 Channel 2'), ('channel 3', 'DAQ 0 Channel 3'), ('channel 4', 'DAQ 0 Channel 4'), ('channel 5', 'DAQ 0 Channel 5'), ('channel 6', 'DAQ 0 Channel 6'), ('channel 7', 'DAQ 0 Channel 7'), ('channel 8', 'DAQ 0 Channel 8'), ('channel 9', 'DAQ 0 Channel 9'), ('channel 10', 'DAQ 0 Channel 10'), ('channel 11', 'DAQ 0 Channel 11'), ('channel 12', 'DAQ 1 Channel 0'), ('channel 13', 'DAQ 1 Channel 1'), ('channel 14', 'DAQ 1 Channel 2'), ('channel 15', 'DAQ 1 Channel 3'), ('channel 16', 'DAQ 1 Channel 4'), ('channel 17', 'DAQ 1 Channel 5'), ('channel 18', 'DAQ 1 Channel 6'), ('channel 19', 'DAQ 1 Channel 7'), ('channel 20', 'DAQ 1 Channel 8'), ('channel 21', 'DAQ 1 Channel 9'), ('channel 22', 'DAQ 1 Channel 10'), ('channel 23', 'DAQ 1 Channel 11'), ('channel 24', 'DAQ 2 Channel 0'), ('channel 25', 'DAQ 2 Channel 1'), ('channel 26', 'DAQ 2 Channel 2'), ('channel 27', 'DAQ 2 Channel 3'), ('channel 28', 'DAQ 2 Channel 4'), ('channel 29', 'DAQ 2 Channel 5'), ('channel 30', 'DAQ 2 Channel 6'), ('channel 31', 'DAQ 2 Channel 7'), ('channel 32', 'DAQ 2 Channel 8'), ('channel 33', 'DAQ 2 Channel 9'), ('channel 34', 'DAQ 2 Channel 10'), ('channel 35', 'DAQ 2 Channel 11'), ('channel 36', 'DAQ 3 Channel 0'), ('channel 37', 'DAQ 3 Channel 1'), ('channel 38', 'DAQ 3 Channel 2'), ('channel 39', 'DAQ 3 Channel 3'), ('channel 40', 'DAQ 3 Channel 4'), ('channel 41', 'DAQ 3 Channel 5'), ('channel 42', 'DAQ 3 Channel 6'), ('channel 43', 'DAQ 3 Channel 7'), ('channel 44', 'DAQ 3 Channel 8'), ('channel 45', 'DAQ 3 Channel 9'), ('channel 46', 'DAQ 3 Channel 10'), ('channel 47', 'DAQ 3 Channel 11')]\n",
    "# lt = [('', 'DAQ 0 Channel 0'), ('channel 1', 'DAQ 0 Channel 1'), ('channel 2', 'DAQ 0 Channel 2'), ('channel 3', 'DAQ 0 Channel 3'), ('channel 4', 'DAQ 0 Channel 4'), ('channel 5', 'DAQ 0 Channel 5'), ('channel 6', 'DAQ 0 Channel 6'), ('channel 7', 'DAQ 0 Channel 7'), ('channel 8', 'DAQ 0 Channel 8'), ('channel 9', 'DAQ 0 Channel 9'), ('channel 10', 'DAQ 0 Channel 10'), ('channel 11', 'DAQ 0 Channel 11'), ('channel 12', 'DAQ 1 Channel 0'), ('channel 13', 'DAQ 1 Channel 1'), ('channel 14', 'DAQ 1 Channel 2'), ('channel 15', 'DAQ 1 Channel 3'), ('channel 16', 'DAQ 1 Channel 4'), ('channel 17', 'DAQ 1 Channel 5'), ('channel 18', 'DAQ 1 Channel 6'), ('channel 19', 'DAQ 1 Channel 7'), ('channel 20', 'DAQ 1 Channel 8'), ('channel 21', 'DAQ 1 Channel 9'), ('channel 22', 'DAQ 1 Channel 10'), ('channel 23', 'DAQ 1 Channel 11'), ('channel 24', 'DAQ 2 Channel 0'), ('channel 25', 'DAQ 2 Channel 1'), ('channel 26', 'DAQ 2 Channel 2'), ('channel 27', 'DAQ 2 Channel 3'), ('channel 28', 'DAQ 2 Channel 4'), ('channel 29', 'DAQ 2 Channel 5'), ('channel 30', 'DAQ 2 Channel 6'), ('channel 31', 'DAQ 2 Channel 7'), ('channel 32', 'DAQ 2 Channel 8'), ('channel 33', 'DAQ 2 Channel 9'), ('channel 34', 'DAQ 2 Channel 10'), ('channel 35', 'DAQ 2 Channel 11'), ('channel 36', 'DAQ 3 Channel 0'), ('channel 37', 'DAQ 3 Channel 1'), ('channel 38', 'DAQ 3 Channel 2'), ('channel 39', 'DAQ 3 Channel 3'), ('channel 40', 'DAQ 3 Channel 4'), ('channel 41', 'DAQ 3 Channel 5'), ('channel 42', 'DAQ 3 Channel 6'), ('channel 43', 'DAQ 3 Channel 7'), ('channel 44', 'DAQ 3 Channel 8'), ('channel 45', 'DAQ 3 Channel 9'), ('channel 46', 'DAQ 3 Channel 10'), ('channel 47', 'DAQ 3 Channel 11')]\n",
    "\n",
    "\n",
    "for i in range(len(newtest)):\n",
    "    print(f\"i: {i}\")\n",
    "    for t in range(12):\n",
    "        # if lt[(i*12) + t][0] == \"\":\n",
    "        #     print(\"boo\")\n",
    "        #     continue\n",
    "        if newtest[i] in lt[(i*12) + t][0]:\n",
    "            print(\"yay\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Error: {newtest[i]} != {lt[(i*12) + t][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test = (0, '360nm')\n",
    "print(type(test))\n",
    "print(test[1][0].isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'January'), (2, 'February'), (3, 'March'), (4, 'April'), (5, 'May'), (6, 'June'), (7, 'July'), (8, 'August'), (9, 'September'), (10, 'October')]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "months = [1,2,3,4,5,6,7,8,9,10]\n",
    "month_labels = [\n",
    "            # Generate a list of tuples (x_value, x_label)\n",
    "            (m, datetime.date(2020, m, 1).strftime('%B'))\n",
    "            for m in months\n",
    "        ]\n",
    "print(month_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packet = file.get(record_n)\n",
    "data1 = packet['event']['data']['adc_data']\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([])\n",
      "dict_keys(['check', 'check1'])\n",
      "Achieved\n",
      "dict_keys(['check', 'check1'])\n",
      "{'check': [0, 1, 2, 3, 4, 5], 'check1': [0, 1, 2, 3, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "temp = {}\n",
    "print(temp.keys())\n",
    "temp[\"check\"] = [0,1,2,3,4,5]\n",
    "temp[\"check1\"] = [0,1,2,3,4,5]\n",
    "\n",
    "n = temp.keys()\n",
    "print(n)\n",
    "if (\"check\" in n) and (\"check1\" in n):\n",
    "    print(\"Achieved\")\n",
    "\n",
    "\n",
    "print(temp.keys())\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with Valery Software\n",
    "\n",
    "Numbers to match or get close to\\\n",
    "471476.88671875 \\\n",
    "717160.87109375 \\\n",
    "726431.96484375 \\\n",
    "742656.37890625 \\\n",
    "744974.15234375 \\\n",
    "1062509.11328125 \\\n",
    "Median gets closest so far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i in range(6):\n",
    "    bigarr1 = torch.from_numpy(data[i].astype(float)).to(device)\n",
    "    # bigarr1 = torch.from_numpy(savgol_filter(data[i], window_length=int(len(data[i][0])/10), polyorder=1, axis=1).astype(float)).to(device)\n",
    "\n",
    "    # a1 = torch.std_mean(bigarr1, dim=0, keepdim=True)\n",
    "    a1 = torch.std(bigarr1, dim=0, keepdim=True)\n",
    "    b1 = torch.mean(bigarr1, dim=0).to(device)\n",
    "    #Height\n",
    "    e1 = (bigarr1.amax(dim=0) - bigarr1.amin(dim=0)).to(device)\n",
    "    # e1 = (bigarr1.amax(dim=1).to(device) - bigarr1.amin(dim=1).to(device)) \n",
    "    # f1 = (bigarr1.lt(b1 - (a1*0.3)) * bigarr1).to(device)\n",
    "    f1 = (bigarr1.lt(b1) * bigarr1).to(device)\n",
    "    #WITDH\n",
    "    g1 = f1.count_nonzero(dim=0).to(device)\n",
    "    #AREA\n",
    "    h1 = ((b1 * g1) - f1.sum(dim=0)).to(device)\n",
    "\n",
    "    # print(a1)\n",
    "    print(\"Height\")\n",
    "    print(e1.cpu().tolist())\n",
    "    print(\"Width\")\n",
    "    print(g1.cpu().tolist())\n",
    "    print(\"Area\")\n",
    "    print(h1.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for i in range(6):\n",
    "    bigarr1 = torch.from_numpy(data[i].astype(float)).to(device)\n",
    "    # bigarr1 = torch.from_numpy(savgol_filter(data[i], window_length=int(data[i][0].__len__()/10), polyorder=1, axis=1).astype(float)).to(device)\n",
    "\n",
    "    a1 = torch.std(bigarr1, dim=0, keepdim=True).to(device)\n",
    "    b1 = torch.median(bigarr1, dim=0)\n",
    "    e1 = (bigarr1.amax(dim=0) - bigarr1.amin(dim=0)).to(device)\n",
    "    # e1 = (bigarr1.amax(dim=1).to(device) - bigarr1.amin(dim=1).to(device)) \n",
    "    f1 = (bigarr1.lt(b1[0]) * bigarr1).to(device)\n",
    "    #WITDH\n",
    "    g1 = f1.count_nonzero(dim=0).to(device)\n",
    "    #AREA\n",
    "    h1 = (((b1[0]) * g1) - f1.sum(dim=0)).to(device)\n",
    "\n",
    "    # print(a1)\n",
    "    print(\"Height\")\n",
    "    print(e1.cpu().tolist())\n",
    "    print(\"Width\")\n",
    "    print(g1.cpu().tolist())\n",
    "    print(\"Area\")\n",
    "    print(h1.cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120hz\n",
      "120hz\n",
      "60hz\n",
      "120hz\n",
      "120hz\n",
      "60hz\n",
      "30hz\n",
      "120hz\n",
      "120hz\n",
      "60hz\n",
      "120hz\n",
      "120hz\n",
      "60hz\n",
      "30hz\n",
      "15hz\n",
      "120hz\n",
      "120hz\n",
      "60hz\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 0\n",
    "t = 0\n",
    "\n",
    "while t < 10:\n",
    "    time.sleep(1/120)\n",
    "    i = (i + 1) % 8\n",
    "    t+=1    \n",
    "    print(\"120hz\")\n",
    "    \n",
    "    if not (i % 2):\n",
    "        print(\"60hz\")\n",
    "    if not (i % 4):\n",
    "        print(\"30hz\")\n",
    "    if (i == 0):\n",
    "        print(\"15hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9]\n",
    "del(a[-1])\n",
    "del(a[-2])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = False\n",
    "WRITE = False if WRITE else True\n",
    "print(WRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 2.33572147e+00 5.45559478e+00 1.27427499e+01\n",
      " 2.97635144e+01 6.95192796e+01 1.62377674e+02 3.79269019e+02\n",
      " 8.85866790e+02 2.06913808e+03 4.83293024e+03 1.12883789e+04\n",
      " 2.63665090e+04 6.15848211e+04 1.43844989e+05 3.35981829e+05\n",
      " 7.84759970e+05 1.83298071e+06 4.28133240e+06 1.00000000e+07]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scale = np.logspace(start=0, stop=7, num = 20)\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "f = open('datafile.csv', 'a')\n",
    "\n",
    "tempH = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','a1','b1','c1','d1','e1','f1','g1','h1','i1','j1','k1','l1','m1','n1','o1','p1','q1','r1','s1','t1','u1','v1']\n",
    "HEADER = []\n",
    "HEADER += tempH\n",
    "HEADER += tempH\n",
    "HEADER += tempH\n",
    "\n",
    "list1 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "list2 = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "list3 = [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]\n",
    "holdlist = list1+list2+list3\n",
    "templist = np.asarray(holdlist)\n",
    "print(templist)\n",
    "# templist = np.asarray((list1,list2,list3))\n",
    "\n",
    "# temp = dict(HEADER, templist)\n",
    "# print(temp)\n",
    "\n",
    "np.savetxt(f, np.transpose(HEADER), delimiter=',', fmt='%s')\n",
    "np.savetxt(f, np.transpose(templist), delimiter=',', fmt='%d')\n",
    "\n",
    "f.close()\n",
    "# df = pd.DataFrame(templist)\n",
    "# df = df.T\n",
    "# print(df)\n",
    "\n",
    "# df1 = pd.DataFrame(HEADER)\n",
    "# df1.to_csv('datafile.csv', sep=',')\n",
    "# df.to_csv('datafile.csv', sep=',', header=HEADER, mode='a')\n",
    "# df.to_csv('datafile.csv', sep=',', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388nm\n",
      "488nm\n",
      "['388nm', '488nm', 'QPD V']\n"
     ]
    }
   ],
   "source": [
    "testlst = ['388nm', 'nc', 'nc', '488nm', 'QPD V']\n",
    "testdict = {0 : '388nm', 1 : 'nc'}\n",
    "\n",
    "# print(testdict.keys())\n",
    "# print(testdict.values())\n",
    "# print(list(testdict.values()).index('388nm'))\n",
    "\n",
    "for i in testlst:\n",
    "    if not i.replace(\" \", \"\").isalpha():\n",
    "        print(i)\n",
    "\n",
    "# g = [i for i in testlst if not i.isalpha()]\n",
    "# print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "q = [1,2,3,4,5,6,7,8]\n",
    "# np.array(1,2,3,4,5, dtype=np.float64)\n",
    "np.array(q, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def funtime(x,y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 4 5]\n",
      " [5 6 7]\n",
      " [7 8 9]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tstlst = np.array(\n",
    "    [[1,2,3],\n",
    "     [3,4,5],\n",
    "     [5,6,7],\n",
    "     [7,8,9]]\n",
    "\n",
    ")\n",
    "\n",
    "print(tstlst[::])\n",
    "# tstlst = tstlst + 1\n",
    "# tstlst = [x+1 for x in tstlst]\n",
    "# print(tstlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['.gitignore', 'databasetest.ipynb', 'dbout1.txt', 'mathing.ipynb', 'out2.txt', 'processingtesting.ipynb', 'processtest.py', 'protobuf.ipynb', 'test.bat', 'test.ini', 'testing.ipynb']\n",
      "['CMakeLists(det).txt']\n",
      "['CMakeLists(det).txt']\n"
     ]
    }
   ],
   "source": [
    "import os, os.path\n",
    "\n",
    "# simple version for working with CWD\n",
    "print (len([name for name in os.listdir('.') if os.path.isfile(name)]))\n",
    "temp = [name for name in os.listdir('.') if os.path.isfile(name)]\n",
    "print(temp)\n",
    "temp = [name for name in os.listdir('./CMAKE')]\n",
    "print(temp)\n",
    "newtemp = []\n",
    "\n",
    "for n in temp:\n",
    "    if '.txt' in n:\n",
    "        newtemp.append(n)\n",
    "\n",
    "print(newtemp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
